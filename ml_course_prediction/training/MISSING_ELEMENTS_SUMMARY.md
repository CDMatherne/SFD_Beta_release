# Missing Elements for save_sequences_cache.py

Based on the last training run analysis, here are the missing elements needed:

## Last Run Parameters (from training.log)

- **Start Date**: `2024-01-01`
- **End Date**: `2024-01-31` (31 days)
- **Vessel Types**: Default `70-89` (vessel types 70 through 89)
- **Historical Data Path**: `C:\AIS_Data_Testing\Historical\2024`
- **Cache Directory**: `C:\Users\chris\OneDrive\Documents\AIS-LLM\LLMWorking_Folder\LLMv1\LLM-MLv1\ml_course_prediction\training\cache`
- **Sequences Directory**: `C:\Users\chris\OneDrive\Documents\AIS-LLM\LLMWorking_Folder\LLMv1\LLM-MLv1\ml_course_prediction\training\cache\sequences`

## Missing Files

### 1. Sequences File (.pkl)
- **Status**: NOT SAVED - sequences exist only in memory
- **What it should contain**: The list of training sequences generated by `prepare_training_sequences()`
- **Where it should be**: Saved to disk after sequences are generated
- **Required by**: `save_sequences_cache.py --sequences-file` argument

### 2. DataFrame File (.parquet)
- **Status**: NOT SAVED - DataFrame exists only in memory  
- **What it should contain**: The full DataFrame (`df_train`) after `load_training_data()` completes
- **Suggested location**: `cache/combined_data_2024-01-01_2024-01-31.parquet`
- **Required by**: `save_sequences_cache.py --data-file` argument

## Current Status

- ✅ Preprocessed daily data is cached: `cache/preprocessed_YYYY_MM_DD_*.parquet`
- ❌ Sequences are NOT saved automatically
- ❌ Combined DataFrame is NOT saved automatically

## Solution

The `train.py` script should be modified to:

1. **Save sequences to disk** after `prepare_training_sequences()` completes:
   ```python
   # After train_sequences are generated
   sequences_file = cache_dir / 'sequences' / f'train_sequences_{start_date}_{end_date}.pkl'
   with open(sequences_file, 'wb') as f:
       pickle.dump(train_sequences, f)
   ```

2. **Save DataFrame to disk** after `load_training_data()` completes:
   ```python
   # After df_train is loaded
   df_file = cache_dir / f'combined_data_{start_date}_{end_date}.parquet'
   df_train.to_parquet(df_file)
   ```

## Usage for save_sequences_cache.py

Once the files are saved, you could run:

```bash
python save_sequences_cache.py \
    --sequences-file "C:\Users\chris\OneDrive\Documents\AIS-LLM\LLMWorking_Folder\LLMv1\LLM-MLv1\ml_course_prediction\training\cache\sequences\train_sequences_2024-01-01_2024-01-31.pkl" \
    --data-file "C:\Users\chris\OneDrive\Documents\AIS-LLM\LLMWorking_Folder\LLMv1\LLM-MLv1\ml_course_prediction\training\cache\combined_data_2024-01-01_2024-01-31.parquet" \
    --start-date 2024-01-01 \
    --end-date 2024-01-31 \
    --vessel-types 70-89
```

## Alternative: Modify train.py to Auto-Save

The `train.py` script should automatically save these files so `save_sequences_cache.py` isn't needed as a separate step.

